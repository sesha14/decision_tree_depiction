{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics when gini criterion is used:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.87      0.93        15\n",
      "           1       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "[[13  2]\n",
      " [ 0 15]]\n",
      "Accuracy: 0.93\n",
      "Logloss: 2.302638399489392\n",
      "\n",
      "Metrics when entropy criterion is used:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.87      0.93        15\n",
      "           1       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "[[13  2]\n",
      " [ 0 15]]\n",
      "Accuracy: 0.93\n",
      "Logloss: 2.302638399489392\n",
      "\n",
      "Accuracy for each depth value when gini criterion is used:\n",
      "\n",
      "depth=1\n",
      "score=0.87\n",
      "\n",
      "depth=2\n",
      "score=0.87\n",
      "\n",
      "depth=3\n",
      "score=0.93\n",
      "\n",
      "depth=4\n",
      "score=0.93\n",
      "\n",
      "depth=5\n",
      "score=0.90\n",
      "\n",
      "depth=6\n",
      "score=0.93\n",
      "\n",
      "Accuracy for each depth value when entropy criterion is used:\n",
      "\n",
      "depth=1\n",
      "score=0.87\n",
      "\n",
      "depth=2\n",
      "score=0.83\n",
      "\n",
      "depth=3\n",
      "score=0.90\n",
      "\n",
      "depth=4\n",
      "score=0.90\n",
      "\n",
      "depth=5\n",
      "score=0.93\n",
      "\n",
      "depth=6\n",
      "score=0.90\n",
      "\n",
      "12 .dot files will be downloaded in Downloads.\n",
      "Please open the .dot files to see the decision tree plots for each of the 12 cases taken above\n"
     ]
    }
   ],
   "source": [
    "# Sesha Sai Sreevani Kappagantula\n",
    "# N11264916\n",
    "# ssk785\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "#X,y values initialization\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "y = df.iloc[50:150, 4].values\n",
    "y = np.where(y == 'Iris-versicolor', -1, 1)\n",
    "X = df.iloc[50:150, [0,1,2,3]].values\n",
    "\n",
    "#split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#train and predict using Decisiontree classifier for all 4 features with gini criterion\n",
    "lr = tree.DecisionTreeClassifier(criterion='gini',max_features=4)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred=lr.predict(X_test)\n",
    "\n",
    "#metrics valuation\n",
    "print('\\nMetrics when gini criterion is used:\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "print('Logloss:',log_loss(y_test,y_pred))\n",
    "\n",
    "#train and predict using Decision tree classifier for all 4 features with entropy criterion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = tree.DecisionTreeClassifier(criterion='entropy',max_features=4)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred=lr.predict(X_test)\n",
    "\n",
    "#metrics valuation\n",
    "print('\\nMetrics when entropy criterion is used:\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "print('Logloss:',log_loss(y_test,y_pred))\n",
    "\n",
    "\n",
    "# List of values to try for max_depth 1,6 depth range:\n",
    "max_depth_range = list(range(1, 7))\n",
    "# List to store the accuracy values for gini criterion for each value of max_depth:\n",
    "\n",
    "print('\\nAccuracy for each depth value when gini criterion is used:')\n",
    "for depth in max_depth_range:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = depth,criterion='gini',max_features=4 \n",
    "                             )\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print('\\ndepth=%d'%depth)\n",
    "    print('score=%.2f'%score)\n",
    "\n",
    "# List to store the accuracy values for entropy criterion for each value of max_depth:\n",
    "print('\\nAccuracy for each depth value when entropy criterion is used:')\n",
    "for depth in max_depth_range:\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier(max_depth = depth,criterion='entropy',max_features=4 \n",
    "                             )\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print('\\ndepth=%d'%depth)\n",
    "    print('score=%.2f'%score)\n",
    "\n",
    "#code for decision tree plotting for iris data \n",
    "\n",
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load data and store it into pandas DataFrame objects\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data[:, :], columns = iris.feature_names[:])\n",
    "y = pd.DataFrame(iris.target, columns =[\"Species\"])\n",
    "\n",
    "#fitting a DecisionTreeClassifier for 6 depth values in 'gini' criterion and plotting .dot files in each case\n",
    "max_depth_range = list(range(1, 7))\n",
    "names=['depth1','depth2','depth3','depth4','depth5','depth6']\n",
    "for i in max_depth_range:\n",
    "    tree = DecisionTreeClassifier(max_depth = i,criterion='gini')\n",
    "    tree.fit(X,y)\n",
    "# Visualize Decision Tree\n",
    "    from sklearn.tree import export_graphviz\n",
    "\n",
    "# Creates dot file named tree.dot\n",
    "    export_graphviz(\n",
    "            tree,\n",
    "            out_file =  \"Tree_gini_\" + names.pop(0)+\".dot\",\n",
    "            feature_names = list(X.columns),\n",
    "            class_names = iris.target_names,\n",
    "            filled = True,\n",
    "            rounded = True)\n",
    "\n",
    "    \n",
    "#fitting a DecisionTreeClassifier for 6 depth values in 'entropy' criterion and plotting .dot files in each case\n",
    "max_depth_range = list(range(1, 7))\n",
    "names=['depth1','depth2','depth3','depth4','depth5','depth6']\n",
    "for i in max_depth_range:\n",
    "    tree = DecisionTreeClassifier(max_depth = i,criterion='entropy')\n",
    "    tree.fit(X,y)\n",
    "# Visualize Decision Tree\n",
    "    from sklearn.tree import export_graphviz\n",
    "\n",
    "# Creates dot file named tree.dot\n",
    "    export_graphviz(\n",
    "            tree,\n",
    "            out_file =  \"Tree_entropy_\" + names.pop(0)+\".dot\",\n",
    "            feature_names = list(X.columns),\n",
    "            class_names = iris.target_names,\n",
    "            filled = True,\n",
    "            rounded = True)\n",
    "\n",
    "\n",
    "print('\\n12 .dot files will be downloaded in Downloads.')\n",
    "print('Please open the .dot files to see the decision tree plots for each of the 12 cases taken above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Conclusion:\n",
    "        -Overall, Gini impurity criterion is giving higher accuracy and lower logloss value than entropy criterion.\n",
    "         \n",
    "        -We also notice that with the increase in depth, accuracy increases but after certain count the\n",
    "         accuracy drops a little.This is because of overfitting.When too many depths are considered, overfitting\n",
    "         occurs leading to drop in accuracy or remains unchanged\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Analysis of depth vs accuracy:\n",
    "\n",
    "    Depths           Accuracy when gini      Accuracy when entropy\n",
    "\n",
    "    Depth 1:               0.8666                 0.8666\n",
    "    Depth 2:               0.8333                 0.8333\n",
    "    Depth 3:               0.8666                 0.9\n",
    "    Depth 4:               0.9333                 0.9\n",
    "    Depth 5:               0.9333                 0.9333\n",
    "    Depth 6:               0.9                    0.9333\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''***Note:: This code when run also produces 12 .dot files (6 files for each of the criterion used.\n",
    "   When the downloaded .dot files are opened we can see the decision tree plot for each case)\n",
    "   Also, if you are only able to view the code on opening the .dot file due to issue with graphviz software on your PC,\n",
    "   please convert the .dot file to png to see the correct depiction of decision tree plot'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
